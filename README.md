# Predictive Maintenance Model

## ‚ú® ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ
‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏°‡∏µ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ã‡πá‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏ã‡∏•‡∏π‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (Predictive Maintenance) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°‡∏ö‡∏≥‡∏£‡∏∏‡∏á ‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡πÄ‡∏ß‡∏•‡∏≤

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Machine Learning ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏∞‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏î False Positives ‡πÅ‡∏•‡∏∞ False Negatives 

## üìÇ Dataset
- **‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤**: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡πá‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå
- **‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢**: ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `failure` (0 = ‡πÑ‡∏°‡πà‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß, 1 = ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß)
- **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ**:
  | Column Name | Description |
  |------------|-------------|
  | `date`     | Date of record |
  | `device`   | Device identifier |
  | `failure`  | Failure occurrence (e.g., 0 = No failure, 1 = Failure) |
  | `metric1` - `metric9` | Various performance metrics |

## üìä ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•
1. **Data Cleaning**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏ç‡∏´‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
2. **Exploratory Data Analysis (EDA)**: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü ‡πÄ‡∏ä‡πà‡∏ô Histogram, Heatmap
3. **Feature Selection & Engineering:**: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ Feature Engineering
4. **Machine Learning Model Development**: ‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ò‡∏∂‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÄ‡∏ä‡πà‡∏ô Logistic Regression, Random Forest
5. **Model Evaluation**: ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å ‡πÄ‡∏ä‡πà‡∏ô Confusion Matrix, Precision, Recall, ROC Curve

## üìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
### Active Devices per Month
![Failure Distribution](https://raw.githubusercontent.com/Pariman1419/Predictive-Maintenance/main/Active Devices per Month.png)

### Heat map 
![Failure Distribution](https://raw.githubusercontent.com/Pariman1419/Predictive-Maintenance/main/Heatmap.png)


### Distribution of Failure
![Failure Distribution](https://raw.githubusercontent.com/Pariman1419/Predictive-Maintenance/main/FailureDistribution.png)

- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö Imbalance ‡∏à‡∏∂‡∏á‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ SMOTE ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ Train model

## üõ†Ô∏è ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
```python

from imblearn.over_sampling import SMOTE
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# ‡πÅ‡∏¢‡∏Å Features ‡πÅ‡∏•‡∏∞ Target
X = df_model.drop(columns=['failure'])
y = df_model['failure']

# ‡πÉ‡∏ä‡πâ SMOTE ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á class ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ô‡πâ‡∏≠‡∏¢
smote = SMOTE(sampling_strategy='minority', random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)


# ‡πÅ‡∏ö‡πà‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (X ‡∏Ñ‡∏∑‡∏≠ Features, y ‡∏Ñ‡∏∑‡∏≠ Target)
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, 
                                                    test_size=0.2, shuffle=True, 
                                                    random_state=42)

# ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Grid Search
best_logreg = grid_search_logreg.best_estimator_
best_tree = grid_search_tree.best_estimator_
best_rf = grid_search_rf.best_estimator_

# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
y_pred_logreg = best_logreg.predict(X_test)
y_pred_tree = best_tree.predict(X_test)
y_pred_rf = best_rf.predict(X_test)

# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
print("Logistic Regression:\n", classification_report(y_test, y_pred_logreg))
print("Decision Tree:\n", classification_report(y_test, y_pred_tree))
print("Random Forest:\n", classification_report(y_test, y_pred_rf))

```
### ROC Curve 

![Failure Distribution](https://raw.githubusercontent.com/Pariman1419/Predictive-Maintenance/main/ROC.png)

# Performance Metrics

### Logistic Regression
```
Precision: 0.71 | Recall: 0.87 | F1-score: 0.78 | Accuracy: 0.76
```

### Decision Tree
```
Precision: 1.00 | Recall: 1.00 | F1-score: 1.00 | Accuracy: 1.00
```

### Random Forest
```
Precision: 1.00 | Recall: 1.00 | F1-score: 1.00 | Accuracy: 1.00
```

